{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a25333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4a9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tensor([[1.0], [2.0], [3.0]])\n",
    "y_data = tensor([[2.0], [4.0], [6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ceeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.linear = torch.nn.Linear(1,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c1d538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Linear(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6844fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f5d6687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84a5b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Model"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac48e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b45d04dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 28.666927337646484\n",
      "Epoch: 1 | Loss: 12.871597290039062\n",
      "Epoch: 2 | Loss: 5.838387966156006\n",
      "Epoch: 3 | Loss: 2.7058441638946533\n",
      "Epoch: 4 | Loss: 1.3097913265228271\n",
      "Epoch: 5 | Loss: 0.6867959499359131\n",
      "Epoch: 6 | Loss: 0.4079657196998596\n",
      "Epoch: 7 | Loss: 0.282369464635849\n",
      "Epoch: 8 | Loss: 0.22500929236412048\n",
      "Epoch: 9 | Loss: 0.19804713129997253\n",
      "Epoch: 10 | Loss: 0.18463757634162903\n",
      "Epoch: 11 | Loss: 0.17728140950202942\n",
      "Epoch: 12 | Loss: 0.17264030873775482\n",
      "Epoch: 13 | Loss: 0.16922709345817566\n",
      "Epoch: 14 | Loss: 0.16638022661209106\n",
      "Epoch: 15 | Loss: 0.16380439698696136\n",
      "Epoch: 16 | Loss: 0.16136808693408966\n",
      "Epoch: 17 | Loss: 0.15901239216327667\n",
      "Epoch: 18 | Loss: 0.15671078860759735\n",
      "Epoch: 19 | Loss: 0.1544513702392578\n",
      "Epoch: 20 | Loss: 0.15222829580307007\n",
      "Epoch: 21 | Loss: 0.15003900229930878\n",
      "Epoch: 22 | Loss: 0.14788225293159485\n",
      "Epoch: 23 | Loss: 0.14575673639774323\n",
      "Epoch: 24 | Loss: 0.14366185665130615\n",
      "Epoch: 25 | Loss: 0.14159706234931946\n",
      "Epoch: 26 | Loss: 0.1395619809627533\n",
      "Epoch: 27 | Loss: 0.13755619525909424\n",
      "Epoch: 28 | Loss: 0.13557955622673035\n",
      "Epoch: 29 | Loss: 0.1336308717727661\n",
      "Epoch: 30 | Loss: 0.1317104697227478\n",
      "Epoch: 31 | Loss: 0.12981757521629333\n",
      "Epoch: 32 | Loss: 0.12795178592205048\n",
      "Epoch: 33 | Loss: 0.1261129528284073\n",
      "Epoch: 34 | Loss: 0.12430061399936676\n",
      "Epoch: 35 | Loss: 0.12251406908035278\n",
      "Epoch: 36 | Loss: 0.12075358629226685\n",
      "Epoch: 37 | Loss: 0.11901801079511642\n",
      "Epoch: 38 | Loss: 0.11730740964412689\n",
      "Epoch: 39 | Loss: 0.1156216561794281\n",
      "Epoch: 40 | Loss: 0.11395998299121857\n",
      "Epoch: 41 | Loss: 0.11232210695743561\n",
      "Epoch: 42 | Loss: 0.11070788651704788\n",
      "Epoch: 43 | Loss: 0.10911688208580017\n",
      "Epoch: 44 | Loss: 0.10754881054162979\n",
      "Epoch: 45 | Loss: 0.10600307583808899\n",
      "Epoch: 46 | Loss: 0.10447952151298523\n",
      "Epoch: 47 | Loss: 0.10297811031341553\n",
      "Epoch: 48 | Loss: 0.10149812698364258\n",
      "Epoch: 49 | Loss: 0.10003938525915146\n",
      "Epoch: 50 | Loss: 0.09860163927078247\n",
      "Epoch: 51 | Loss: 0.09718464314937592\n",
      "Epoch: 52 | Loss: 0.09578803926706314\n",
      "Epoch: 53 | Loss: 0.0944114550948143\n",
      "Epoch: 54 | Loss: 0.09305457025766373\n",
      "Epoch: 55 | Loss: 0.09171715378761292\n",
      "Epoch: 56 | Loss: 0.09039895236492157\n",
      "Epoch: 57 | Loss: 0.08909990638494492\n",
      "Epoch: 58 | Loss: 0.087819404900074\n",
      "Epoch: 59 | Loss: 0.08655722439289093\n",
      "Epoch: 60 | Loss: 0.08531320095062256\n",
      "Epoch: 61 | Loss: 0.0840870812535286\n",
      "Epoch: 62 | Loss: 0.08287866413593292\n",
      "Epoch: 63 | Loss: 0.08168765157461166\n",
      "Epoch: 64 | Loss: 0.08051371574401855\n",
      "Epoch: 65 | Loss: 0.07935653626918793\n",
      "Epoch: 66 | Loss: 0.07821614295244217\n",
      "Epoch: 67 | Loss: 0.07709191739559174\n",
      "Epoch: 68 | Loss: 0.07598410546779633\n",
      "Epoch: 69 | Loss: 0.07489200681447983\n",
      "Epoch: 70 | Loss: 0.07381577044725418\n",
      "Epoch: 71 | Loss: 0.07275472581386566\n",
      "Epoch: 72 | Loss: 0.07170922309160233\n",
      "Epoch: 73 | Loss: 0.0706786960363388\n",
      "Epoch: 74 | Loss: 0.06966287642717361\n",
      "Epoch: 75 | Loss: 0.06866175681352615\n",
      "Epoch: 76 | Loss: 0.06767504662275314\n",
      "Epoch: 77 | Loss: 0.06670229882001877\n",
      "Epoch: 78 | Loss: 0.06574372202157974\n",
      "Epoch: 79 | Loss: 0.06479893624782562\n",
      "Epoch: 80 | Loss: 0.06386760622262955\n",
      "Epoch: 81 | Loss: 0.0629497691988945\n",
      "Epoch: 82 | Loss: 0.06204507499933243\n",
      "Epoch: 83 | Loss: 0.06115337088704109\n",
      "Epoch: 84 | Loss: 0.06027447432279587\n",
      "Epoch: 85 | Loss: 0.05940825119614601\n",
      "Epoch: 86 | Loss: 0.05855448171496391\n",
      "Epoch: 87 | Loss: 0.05771292373538017\n",
      "Epoch: 88 | Loss: 0.05688358098268509\n",
      "Epoch: 89 | Loss: 0.05606600269675255\n",
      "Epoch: 90 | Loss: 0.05526026710867882\n",
      "Epoch: 91 | Loss: 0.054466165602207184\n",
      "Epoch: 92 | Loss: 0.053683217614889145\n",
      "Epoch: 93 | Loss: 0.05291171371936798\n",
      "Epoch: 94 | Loss: 0.05215128883719444\n",
      "Epoch: 95 | Loss: 0.051401905715465546\n",
      "Epoch: 96 | Loss: 0.050663165748119354\n",
      "Epoch: 97 | Loss: 0.049935080111026764\n",
      "Epoch: 98 | Loss: 0.04921750724315643\n",
      "Epoch: 99 | Loss: 0.04851006343960762\n",
      "Epoch: 100 | Loss: 0.0478128157556057\n",
      "Epoch: 101 | Loss: 0.04712573438882828\n",
      "Epoch: 102 | Loss: 0.04644841328263283\n",
      "Epoch: 103 | Loss: 0.04578092321753502\n",
      "Epoch: 104 | Loss: 0.04512294381856918\n",
      "Epoch: 105 | Loss: 0.04447449743747711\n",
      "Epoch: 106 | Loss: 0.043835319578647614\n",
      "Epoch: 107 | Loss: 0.04320526868104935\n",
      "Epoch: 108 | Loss: 0.04258444532752037\n",
      "Epoch: 109 | Loss: 0.04197237268090248\n",
      "Epoch: 110 | Loss: 0.041369229555130005\n",
      "Epoch: 111 | Loss: 0.040774669498205185\n",
      "Epoch: 112 | Loss: 0.040188707411289215\n",
      "Epoch: 113 | Loss: 0.03961104154586792\n",
      "Epoch: 114 | Loss: 0.03904183208942413\n",
      "Epoch: 115 | Loss: 0.03848065435886383\n",
      "Epoch: 116 | Loss: 0.03792772442102432\n",
      "Epoch: 117 | Loss: 0.037382617592811584\n",
      "Epoch: 118 | Loss: 0.036845311522483826\n",
      "Epoch: 119 | Loss: 0.03631578013300896\n",
      "Epoch: 120 | Loss: 0.035793956369161606\n",
      "Epoch: 121 | Loss: 0.03527950122952461\n",
      "Epoch: 122 | Loss: 0.03477247804403305\n",
      "Epoch: 123 | Loss: 0.03427278250455856\n",
      "Epoch: 124 | Loss: 0.03378017991781235\n",
      "Epoch: 125 | Loss: 0.033294741064310074\n",
      "Epoch: 126 | Loss: 0.03281624615192413\n",
      "Epoch: 127 | Loss: 0.03234459459781647\n",
      "Epoch: 128 | Loss: 0.03187977150082588\n",
      "Epoch: 129 | Loss: 0.03142160549759865\n",
      "Epoch: 130 | Loss: 0.030969984829425812\n",
      "Epoch: 131 | Loss: 0.030524883419275284\n",
      "Epoch: 132 | Loss: 0.03008626215159893\n",
      "Epoch: 133 | Loss: 0.029653867706656456\n",
      "Epoch: 134 | Loss: 0.02922765351831913\n",
      "Epoch: 135 | Loss: 0.02880762331187725\n",
      "Epoch: 136 | Loss: 0.02839372120797634\n",
      "Epoch: 137 | Loss: 0.027985477820038795\n",
      "Epoch: 138 | Loss: 0.027583369985222816\n",
      "Epoch: 139 | Loss: 0.027186978608369827\n",
      "Epoch: 140 | Loss: 0.026796218007802963\n",
      "Epoch: 141 | Loss: 0.02641112729907036\n",
      "Epoch: 142 | Loss: 0.026031602174043655\n",
      "Epoch: 143 | Loss: 0.0256574135273695\n",
      "Epoch: 144 | Loss: 0.025288699194788933\n",
      "Epoch: 145 | Loss: 0.02492527663707733\n",
      "Epoch: 146 | Loss: 0.02456703782081604\n",
      "Epoch: 147 | Loss: 0.024213988333940506\n",
      "Epoch: 148 | Loss: 0.023865964263677597\n",
      "Epoch: 149 | Loss: 0.02352300100028515\n",
      "Epoch: 150 | Loss: 0.023184964433312416\n",
      "Epoch: 151 | Loss: 0.02285172790288925\n",
      "Epoch: 152 | Loss: 0.022523323073983192\n",
      "Epoch: 153 | Loss: 0.02219962328672409\n",
      "Epoch: 154 | Loss: 0.021880580112338066\n",
      "Epoch: 155 | Loss: 0.021566078066825867\n",
      "Epoch: 156 | Loss: 0.021256139501929283\n",
      "Epoch: 157 | Loss: 0.02095070853829384\n",
      "Epoch: 158 | Loss: 0.020649608224630356\n",
      "Epoch: 159 | Loss: 0.02035277709364891\n",
      "Epoch: 160 | Loss: 0.02006029710173607\n",
      "Epoch: 161 | Loss: 0.01977202482521534\n",
      "Epoch: 162 | Loss: 0.01948785036802292\n",
      "Epoch: 163 | Loss: 0.019207807257771492\n",
      "Epoch: 164 | Loss: 0.018931781873106956\n",
      "Epoch: 165 | Loss: 0.018659675493836403\n",
      "Epoch: 166 | Loss: 0.018391558900475502\n",
      "Epoch: 167 | Loss: 0.018127165734767914\n",
      "Epoch: 168 | Loss: 0.017866678535938263\n",
      "Epoch: 169 | Loss: 0.0176098495721817\n",
      "Epoch: 170 | Loss: 0.017356794327497482\n",
      "Epoch: 171 | Loss: 0.01710735820233822\n",
      "Epoch: 172 | Loss: 0.01686149463057518\n",
      "Epoch: 173 | Loss: 0.016619201749563217\n",
      "Epoch: 174 | Loss: 0.01638033054769039\n",
      "Epoch: 175 | Loss: 0.016144907101988792\n",
      "Epoch: 176 | Loss: 0.015912922099232674\n",
      "Epoch: 177 | Loss: 0.015684209764003754\n",
      "Epoch: 178 | Loss: 0.015458821319043636\n",
      "Epoch: 179 | Loss: 0.015236664563417435\n",
      "Epoch: 180 | Loss: 0.015017669647932053\n",
      "Epoch: 181 | Loss: 0.01480183843523264\n",
      "Epoch: 182 | Loss: 0.014589044265449047\n",
      "Epoch: 183 | Loss: 0.014379477128386497\n",
      "Epoch: 184 | Loss: 0.014172811061143875\n",
      "Epoch: 185 | Loss: 0.01396906841546297\n",
      "Epoch: 186 | Loss: 0.01376837957650423\n",
      "Epoch: 187 | Loss: 0.013570468872785568\n",
      "Epoch: 188 | Loss: 0.013375436887145042\n",
      "Epoch: 189 | Loss: 0.013183225877583027\n",
      "Epoch: 190 | Loss: 0.012993691489100456\n",
      "Epoch: 191 | Loss: 0.012806950137019157\n",
      "Epoch: 192 | Loss: 0.01262291893362999\n",
      "Epoch: 193 | Loss: 0.012441550381481647\n",
      "Epoch: 194 | Loss: 0.012262729927897453\n",
      "Epoch: 195 | Loss: 0.012086495757102966\n",
      "Epoch: 196 | Loss: 0.011912811547517776\n",
      "Epoch: 197 | Loss: 0.011741576716303825\n",
      "Epoch: 198 | Loss: 0.011572837829589844\n",
      "Epoch: 199 | Loss: 0.011406481266021729\n",
      "Epoch: 200 | Loss: 0.011242599226534367\n",
      "Epoch: 201 | Loss: 0.011080967262387276\n",
      "Epoch: 202 | Loss: 0.010921794921159744\n",
      "Epoch: 203 | Loss: 0.01076478697359562\n",
      "Epoch: 204 | Loss: 0.010610096156597137\n",
      "Epoch: 205 | Loss: 0.010457576252520084\n",
      "Epoch: 206 | Loss: 0.010307353921234608\n",
      "Epoch: 207 | Loss: 0.010159144178032875\n",
      "Epoch: 208 | Loss: 0.01001323014497757\n",
      "Epoch: 209 | Loss: 0.009869271889328957\n",
      "Epoch: 210 | Loss: 0.009727434255182743\n",
      "Epoch: 211 | Loss: 0.00958764273673296\n",
      "Epoch: 212 | Loss: 0.00944981724023819\n",
      "Epoch: 213 | Loss: 0.009314017370343208\n",
      "Epoch: 214 | Loss: 0.009180180728435516\n",
      "Epoch: 215 | Loss: 0.00904824212193489\n",
      "Epoch: 216 | Loss: 0.008918180130422115\n",
      "Epoch: 217 | Loss: 0.008790019899606705\n",
      "Epoch: 218 | Loss: 0.008663744665682316\n",
      "Epoch: 219 | Loss: 0.008539225906133652\n",
      "Epoch: 220 | Loss: 0.008416484110057354\n",
      "Epoch: 221 | Loss: 0.008295495063066483\n",
      "Epoch: 222 | Loss: 0.008176300674676895\n",
      "Epoch: 223 | Loss: 0.008058814331889153\n",
      "Epoch: 224 | Loss: 0.007942971773445606\n",
      "Epoch: 225 | Loss: 0.007828837260603905\n",
      "Epoch: 226 | Loss: 0.007716284599155188\n",
      "Epoch: 227 | Loss: 0.00760543392971158\n",
      "Epoch: 228 | Loss: 0.0074961003847420216\n",
      "Epoch: 229 | Loss: 0.007388398051261902\n",
      "Epoch: 230 | Loss: 0.0072821942158043385\n",
      "Epoch: 231 | Loss: 0.007177538238465786\n",
      "Epoch: 232 | Loss: 0.007074391469359398\n",
      "Epoch: 233 | Loss: 0.006972730625420809\n",
      "Epoch: 234 | Loss: 0.006872484926134348\n",
      "Epoch: 235 | Loss: 0.006773711182177067\n",
      "Epoch: 236 | Loss: 0.0066764079965651035\n",
      "Epoch: 237 | Loss: 0.006580403074622154\n",
      "Epoch: 238 | Loss: 0.006485884077847004\n",
      "Epoch: 239 | Loss: 0.0063926540315151215\n",
      "Epoch: 240 | Loss: 0.0063007911667227745\n",
      "Epoch: 241 | Loss: 0.006210239604115486\n",
      "Epoch: 242 | Loss: 0.006120961159467697\n",
      "Epoch: 243 | Loss: 0.006032993551343679\n",
      "Epoch: 244 | Loss: 0.005946308374404907\n",
      "Epoch: 245 | Loss: 0.005860837642103434\n",
      "Epoch: 246 | Loss: 0.005776591598987579\n",
      "Epoch: 247 | Loss: 0.005693604238331318\n",
      "Epoch: 248 | Loss: 0.005611740052700043\n",
      "Epoch: 249 | Loss: 0.0055311089381575584\n",
      "Epoch: 250 | Loss: 0.00545161496847868\n",
      "Epoch: 251 | Loss: 0.0053732628002762794\n",
      "Epoch: 252 | Loss: 0.005296084098517895\n",
      "Epoch: 253 | Loss: 0.005219975020736456\n",
      "Epoch: 254 | Loss: 0.005144938826560974\n",
      "Epoch: 255 | Loss: 0.005070996005088091\n",
      "Epoch: 256 | Loss: 0.004998119082301855\n",
      "Epoch: 257 | Loss: 0.004926283378154039\n",
      "Epoch: 258 | Loss: 0.004855478648096323\n",
      "Epoch: 259 | Loss: 0.004785701632499695\n",
      "Epoch: 260 | Loss: 0.004716903902590275\n",
      "Epoch: 261 | Loss: 0.0046491436660289764\n",
      "Epoch: 262 | Loss: 0.004582311026751995\n",
      "Epoch: 263 | Loss: 0.00451648561283946\n",
      "Epoch: 264 | Loss: 0.004451547749340534\n",
      "Epoch: 265 | Loss: 0.004387596156448126\n",
      "Epoch: 266 | Loss: 0.004324542824178934\n",
      "Epoch: 267 | Loss: 0.004262394271790981\n",
      "Epoch: 268 | Loss: 0.00420111371204257\n",
      "Epoch: 269 | Loss: 0.004140721634030342\n",
      "Epoch: 270 | Loss: 0.004081250634044409\n",
      "Epoch: 271 | Loss: 0.004022584762424231\n",
      "Epoch: 272 | Loss: 0.003964783623814583\n",
      "Epoch: 273 | Loss: 0.003907789941877127\n",
      "Epoch: 274 | Loss: 0.0038516344502568245\n",
      "Epoch: 275 | Loss: 0.003796282922849059\n",
      "Epoch: 276 | Loss: 0.0037417339626699686\n",
      "Epoch: 277 | Loss: 0.0036879503168165684\n",
      "Epoch: 278 | Loss: 0.0036349419970065355\n",
      "Epoch: 279 | Loss: 0.0035827141255140305\n",
      "Epoch: 280 | Loss: 0.0035311956889927387\n",
      "Epoch: 281 | Loss: 0.00348046887665987\n",
      "Epoch: 282 | Loss: 0.0034304563887417316\n",
      "Epoch: 283 | Loss: 0.0033811405301094055\n",
      "Epoch: 284 | Loss: 0.0033325545955449343\n",
      "Epoch: 285 | Loss: 0.0032846699468791485\n",
      "Epoch: 286 | Loss: 0.0032374493312090635\n",
      "Epoch: 287 | Loss: 0.003190915333107114\n",
      "Epoch: 288 | Loss: 0.0031450644601136446\n",
      "Epoch: 289 | Loss: 0.0030998524744063616\n",
      "Epoch: 290 | Loss: 0.003055334324017167\n",
      "Epoch: 291 | Loss: 0.003011399880051613\n",
      "Epoch: 292 | Loss: 0.0029681127052754164\n",
      "Epoch: 293 | Loss: 0.0029254474211484194\n",
      "Epoch: 294 | Loss: 0.0028834156692028046\n",
      "Epoch: 295 | Loss: 0.0028419855516403913\n",
      "Epoch: 296 | Loss: 0.0028011321555823088\n",
      "Epoch: 297 | Loss: 0.002760880161076784\n",
      "Epoch: 298 | Loss: 0.0027212046552449465\n",
      "Epoch: 299 | Loss: 0.0026820842176675797\n",
      "Epoch: 300 | Loss: 0.0026435251347720623\n",
      "Epoch: 301 | Loss: 0.002605568617582321\n",
      "Epoch: 302 | Loss: 0.0025681164115667343\n",
      "Epoch: 303 | Loss: 0.002531216247007251\n",
      "Epoch: 304 | Loss: 0.0024948357604444027\n",
      "Epoch: 305 | Loss: 0.0024589435197412968\n",
      "Epoch: 306 | Loss: 0.0024236231110990047\n",
      "Epoch: 307 | Loss: 0.002388780005276203\n",
      "Epoch: 308 | Loss: 0.002354454481974244\n",
      "Epoch: 309 | Loss: 0.0023206379264593124\n",
      "Epoch: 310 | Loss: 0.0022872881963849068\n",
      "Epoch: 311 | Loss: 0.0022544092498719692\n",
      "Epoch: 312 | Loss: 0.002222031122073531\n",
      "Epoch: 313 | Loss: 0.0021900779101997614\n",
      "Epoch: 314 | Loss: 0.0021585910581052303\n",
      "Epoch: 315 | Loss: 0.0021275710314512253\n",
      "Epoch: 316 | Loss: 0.0020969989709556103\n",
      "Epoch: 317 | Loss: 0.0020668834913522005\n",
      "Epoch: 318 | Loss: 0.0020371696446090937\n",
      "Epoch: 319 | Loss: 0.0020078765228390694\n",
      "Epoch: 320 | Loss: 0.001979026012122631\n",
      "Epoch: 321 | Loss: 0.0019505819072946906\n",
      "Epoch: 322 | Loss: 0.0019225527066737413\n",
      "Epoch: 323 | Loss: 0.001894936547614634\n",
      "Epoch: 324 | Loss: 0.0018676833715289831\n",
      "Epoch: 325 | Loss: 0.0018408321775496006\n",
      "Epoch: 326 | Loss: 0.0018144010100513697\n",
      "Epoch: 327 | Loss: 0.00178832549136132\n",
      "Epoch: 328 | Loss: 0.0017626022454351187\n",
      "Epoch: 329 | Loss: 0.0017372858710587025\n",
      "Epoch: 330 | Loss: 0.0017123090801760554\n",
      "Epoch: 331 | Loss: 0.0016877161106094718\n",
      "Epoch: 332 | Loss: 0.0016634316416457295\n",
      "Epoch: 333 | Loss: 0.0016395419370383024\n",
      "Epoch: 334 | Loss: 0.0016159838996827602\n",
      "Epoch: 335 | Loss: 0.0015927520580589771\n",
      "Epoch: 336 | Loss: 0.0015698724891990423\n",
      "Epoch: 337 | Loss: 0.001547298044897616\n",
      "Epoch: 338 | Loss: 0.0015250801807269454\n",
      "Epoch: 339 | Loss: 0.0015031469520181417\n",
      "Epoch: 340 | Loss: 0.0014815472532063723\n",
      "Epoch: 341 | Loss: 0.0014602502342313528\n",
      "Epoch: 342 | Loss: 0.0014392728917300701\n",
      "Epoch: 343 | Loss: 0.0014185766922309995\n",
      "Epoch: 344 | Loss: 0.001398180378600955\n",
      "Epoch: 345 | Loss: 0.0013781064189970493\n",
      "Epoch: 346 | Loss: 0.0013582870597019792\n",
      "Epoch: 347 | Loss: 0.001338775036856532\n",
      "Epoch: 348 | Loss: 0.0013195413630455732\n",
      "Epoch: 349 | Loss: 0.001300579053349793\n",
      "Epoch: 350 | Loss: 0.0012818726245313883\n",
      "Epoch: 351 | Loss: 0.0012634608428925276\n",
      "Epoch: 352 | Loss: 0.001245299237780273\n",
      "Epoch: 353 | Loss: 0.00122741365339607\n",
      "Epoch: 354 | Loss: 0.0012097686994820833\n",
      "Epoch: 355 | Loss: 0.0011923781130462885\n",
      "Epoch: 356 | Loss: 0.0011752448044717312\n",
      "Epoch: 357 | Loss: 0.001158360275439918\n",
      "Epoch: 358 | Loss: 0.0011416961206123233\n",
      "Epoch: 359 | Loss: 0.0011252912227064371\n",
      "Epoch: 360 | Loss: 0.0011091327760368586\n",
      "Epoch: 361 | Loss: 0.001093181548640132\n",
      "Epoch: 362 | Loss: 0.0010774832917377353\n",
      "Epoch: 363 | Loss: 0.001061993301846087\n",
      "Epoch: 364 | Loss: 0.0010467283427715302\n",
      "Epoch: 365 | Loss: 0.0010316839907318354\n",
      "Epoch: 366 | Loss: 0.0010168469743803144\n",
      "Epoch: 367 | Loss: 0.001002238830551505\n",
      "Epoch: 368 | Loss: 0.0009878368582576513\n",
      "Epoch: 369 | Loss: 0.0009736262145452201\n",
      "Epoch: 370 | Loss: 0.0009596464224159718\n",
      "Epoch: 371 | Loss: 0.0009458589483983815\n",
      "Epoch: 372 | Loss: 0.000932265305891633\n",
      "Epoch: 373 | Loss: 0.0009188652038574219\n",
      "Epoch: 374 | Loss: 0.0009056479320861399\n",
      "Epoch: 375 | Loss: 0.0008926304872147739\n",
      "Epoch: 376 | Loss: 0.0008797987829893827\n",
      "Epoch: 377 | Loss: 0.0008671644027344882\n",
      "Epoch: 378 | Loss: 0.0008547115721739829\n",
      "Epoch: 379 | Loss: 0.0008424212574027479\n",
      "Epoch: 380 | Loss: 0.0008303054491989315\n",
      "Epoch: 381 | Loss: 0.0008183788741007447\n",
      "Epoch: 382 | Loss: 0.0008066276786848903\n",
      "Epoch: 383 | Loss: 0.0007950320141389966\n",
      "Epoch: 384 | Loss: 0.0007836066070012748\n",
      "Epoch: 385 | Loss: 0.0007723495364189148\n",
      "Epoch: 386 | Loss: 0.000761239614803344\n",
      "Epoch: 387 | Loss: 0.0007503009401261806\n",
      "Epoch: 388 | Loss: 0.0007395095308311284\n",
      "Epoch: 389 | Loss: 0.0007288872729986906\n",
      "Epoch: 390 | Loss: 0.0007184259593486786\n",
      "Epoch: 391 | Loss: 0.0007080914219841361\n",
      "Epoch: 392 | Loss: 0.0006979177123866975\n",
      "Epoch: 393 | Loss: 0.0006878877757117152\n",
      "Epoch: 394 | Loss: 0.0006779971299692988\n",
      "Epoch: 395 | Loss: 0.0006682577077299356\n",
      "Epoch: 396 | Loss: 0.0006586543750017881\n",
      "Epoch: 397 | Loss: 0.0006491887615993619\n",
      "Epoch: 398 | Loss: 0.0006398577825166285\n",
      "Epoch: 399 | Loss: 0.0006306556751951575\n",
      "Epoch: 400 | Loss: 0.0006216014153324068\n",
      "Epoch: 401 | Loss: 0.0006126644439063966\n",
      "Epoch: 402 | Loss: 0.0006038550636731088\n",
      "Epoch: 403 | Loss: 0.0005951732746325433\n",
      "Epoch: 404 | Loss: 0.0005866205901838839\n",
      "Epoch: 405 | Loss: 0.0005781982326880097\n",
      "Epoch: 406 | Loss: 0.0005698923487216234\n",
      "Epoch: 407 | Loss: 0.0005617044516839087\n",
      "Epoch: 408 | Loss: 0.0005536209209822118\n",
      "Epoch: 409 | Loss: 0.000545655726455152\n",
      "Epoch: 410 | Loss: 0.0005378278438001871\n",
      "Epoch: 411 | Loss: 0.0005300939665175974\n",
      "Epoch: 412 | Loss: 0.0005224719643592834\n",
      "Epoch: 413 | Loss: 0.0005149684147909284\n",
      "Epoch: 414 | Loss: 0.0005075702792964876\n",
      "Epoch: 415 | Loss: 0.0005002659745514393\n",
      "Epoch: 416 | Loss: 0.0004930817522108555\n",
      "Epoch: 417 | Loss: 0.0004859879263676703\n",
      "Epoch: 418 | Loss: 0.0004790180246345699\n",
      "Epoch: 419 | Loss: 0.00047213135985657573\n",
      "Epoch: 420 | Loss: 0.00046533718705177307\n",
      "Epoch: 421 | Loss: 0.0004586532595567405\n",
      "Epoch: 422 | Loss: 0.00045205847709439695\n",
      "Epoch: 423 | Loss: 0.00044556299690157175\n",
      "Epoch: 424 | Loss: 0.00043916451977565885\n",
      "Epoch: 425 | Loss: 0.00043284977436996996\n",
      "Epoch: 426 | Loss: 0.0004266348259989172\n",
      "Epoch: 427 | Loss: 0.00042050055344589055\n",
      "Epoch: 428 | Loss: 0.00041446281829848886\n",
      "Epoch: 429 | Loss: 0.0004085063701495528\n",
      "Epoch: 430 | Loss: 0.00040262567927129567\n",
      "Epoch: 431 | Loss: 0.0003968478413298726\n",
      "Epoch: 432 | Loss: 0.00039113935781642795\n",
      "Epoch: 433 | Loss: 0.0003855213290080428\n",
      "Epoch: 434 | Loss: 0.00037998019251972437\n",
      "Epoch: 435 | Loss: 0.00037452083779498935\n",
      "Epoch: 436 | Loss: 0.0003691434394568205\n",
      "Epoch: 437 | Loss: 0.00036382596590556204\n",
      "Epoch: 438 | Loss: 0.0003586065140552819\n",
      "Epoch: 439 | Loss: 0.00035345106152817607\n",
      "Epoch: 440 | Loss: 0.00034837305429391563\n",
      "Epoch: 441 | Loss: 0.0003433619567658752\n",
      "Epoch: 442 | Loss: 0.00033842891571111977\n",
      "Epoch: 443 | Loss: 0.0003335548972245306\n",
      "Epoch: 444 | Loss: 0.00032877002377063036\n",
      "Epoch: 445 | Loss: 0.00032404583180323243\n",
      "Epoch: 446 | Loss: 0.00031938496977090836\n",
      "Epoch: 447 | Loss: 0.0003147950046695769\n",
      "Epoch: 448 | Loss: 0.0003102710179518908\n",
      "Epoch: 449 | Loss: 0.0003058183938264847\n",
      "Epoch: 450 | Loss: 0.0003014201938640326\n",
      "Epoch: 451 | Loss: 0.0002970909408759326\n",
      "Epoch: 452 | Loss: 0.000292814860586077\n",
      "Epoch: 453 | Loss: 0.00028861325699836016\n",
      "Epoch: 454 | Loss: 0.00028445967473089695\n",
      "Epoch: 455 | Loss: 0.0002803702955134213\n",
      "Epoch: 456 | Loss: 0.0002763452648650855\n",
      "Epoch: 457 | Loss: 0.0002723800716921687\n",
      "Epoch: 458 | Loss: 0.00026845879619941115\n",
      "Epoch: 459 | Loss: 0.0002645990171004087\n",
      "Epoch: 460 | Loss: 0.00026079631061293185\n",
      "Epoch: 461 | Loss: 0.0002570481738075614\n",
      "Epoch: 462 | Loss: 0.0002533558290451765\n",
      "Epoch: 463 | Loss: 0.0002497177920304239\n",
      "Epoch: 464 | Loss: 0.0002461279509589076\n",
      "Epoch: 465 | Loss: 0.0002425885177217424\n",
      "Epoch: 466 | Loss: 0.00023910263553261757\n",
      "Epoch: 467 | Loss: 0.00023566158779431134\n",
      "Epoch: 468 | Loss: 0.00023227737983688712\n",
      "Epoch: 469 | Loss: 0.00022893966524861753\n",
      "Epoch: 470 | Loss: 0.00022565053950529546\n",
      "Epoch: 471 | Loss: 0.00022240515681914985\n",
      "Epoch: 472 | Loss: 0.00021920999279245734\n",
      "Epoch: 473 | Loss: 0.00021606270456686616\n",
      "Epoch: 474 | Loss: 0.00021295007900334895\n",
      "Epoch: 475 | Loss: 0.0002098928962368518\n",
      "Epoch: 476 | Loss: 0.0002068745088763535\n",
      "Epoch: 477 | Loss: 0.0002039062383119017\n",
      "Epoch: 478 | Loss: 0.00020097506057936698\n",
      "Epoch: 479 | Loss: 0.0001980912929866463\n",
      "Epoch: 480 | Loss: 0.00019523325318004936\n",
      "Epoch: 481 | Loss: 0.00019243145652581006\n",
      "Epoch: 482 | Loss: 0.0001896643079817295\n",
      "Epoch: 483 | Loss: 0.0001869458646979183\n",
      "Epoch: 484 | Loss: 0.00018425806774757802\n",
      "Epoch: 485 | Loss: 0.00018160852778237313\n",
      "Epoch: 486 | Loss: 0.00017899996601045132\n",
      "Epoch: 487 | Loss: 0.00017642804596107453\n",
      "Epoch: 488 | Loss: 0.00017388546257279813\n",
      "Epoch: 489 | Loss: 0.0001713864621706307\n",
      "Epoch: 490 | Loss: 0.00016892518033273518\n",
      "Epoch: 491 | Loss: 0.00016649447206873447\n",
      "Epoch: 492 | Loss: 0.0001641029812162742\n",
      "Epoch: 493 | Loss: 0.0001617472735233605\n",
      "Epoch: 494 | Loss: 0.0001594240020494908\n",
      "Epoch: 495 | Loss: 0.00015712628373876214\n",
      "Epoch: 496 | Loss: 0.00015487564087379724\n",
      "Epoch: 497 | Loss: 0.00015265130787156522\n",
      "Epoch: 498 | Loss: 0.0001504515967098996\n",
      "Epoch: 499 | Loss: 0.00014829546853434294\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    y_pred = model.forward(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(f'Epoch: {epoch} | Loss: {loss.item()}')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c61d68a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (after training) 4 7.986001968383789\n"
     ]
    }
   ],
   "source": [
    "hour_var =tensor([4.0])\n",
    "y_pred = model(hour_var)\n",
    "print(\"Prediction (after training)\", 4, y_pred.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b37f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
